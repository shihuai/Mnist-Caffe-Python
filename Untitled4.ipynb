{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert train.csv to lmdb\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmdb\n",
    "import cv2\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "DATA_ROOT = '/home/shihuai02/caffe/examples/mnist'\n",
    "join = os.path.join\n",
    "TRAIN = join(DATA_ROOT, 'train.csv')\n",
    "train_file = join(DATA_ROOT, 'mnist_train_lmdb1')\n",
    "test_file = join(DATA_ROOT, 'mnist_test_lmdb1')\n",
    "\n",
    "# logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "# load data from train.csv\n",
    "logger.info('Load data from %s', TRAIN)\n",
    "df = pd.read_csv(TRAIN)\n",
    "data = df.values\n",
    "\n",
    "logger.info('Get %d Rows in dataset', len(data))\n",
    "\n",
    "# random shuffle\n",
    "np.random.shuffle(data)\n",
    "np.fromstring(data, dtype=np.uint8)\n",
    "\n",
    "# all dataset\n",
    "labels = data[:, 0]\n",
    "images = data[:, 1:]\n",
    "\n",
    "# process data\n",
    "images = images.reshape((len(images), 1, 28, 28))\n",
    "\n",
    "# train dataset number\n",
    "trainset = len(labels) * 3 / 4\n",
    "\n",
    "# train dataset\n",
    "labels_train = labels[:trainset]\n",
    "images_train = images[:trainset]\n",
    "# test dataset\n",
    "labels_test = labels[trainset:]\n",
    "images_test = images[trainset:]    \n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "# create the leveldb file\n",
    "lmdb_env = lmdb.open(train_file, map_size=int(1e12))\n",
    "lmdb_txn = lmdb_env.begin(write=True)\n",
    "datum = caffe_pb2.Datum()\n",
    "\n",
    "item_id = -1\n",
    "logger.info('Write train dataset to %s', train_file)\n",
    "for x in range(trainset):\n",
    "    item_id += 1\n",
    "\n",
    "    # save in datum\n",
    "    datum = caffe.io.array_to_datum(images_train[x], labels_train[x])\n",
    "    keystr = '{:0>8d}'.format(item_id)\n",
    "    lmdb_txn.put( keystr, datum.SerializeToString() )\n",
    "\n",
    "    # write batch\n",
    "    if(item_id + 1) % batch_size == 0:\n",
    "        lmdb_txn.commit()\n",
    "        lmdb_txn = lmdb_env.begin(write=True)\n",
    "        print (item_id + 1)\n",
    "        \n",
    "if (item_id+1) % batch_size != 0:\n",
    "    lmdb_txn.commit()\n",
    "    print 'last train batch'\n",
    "    print (item_id + 1) \n",
    "\n",
    "lmdb_env.close()\n",
    "lmdb_env = lmdb.open(test_file, map_size=int(1e12))\n",
    "lmdb_txn = lmdb_env.begin(write=True)\n",
    "datum = caffe_pb2.Datum()\n",
    "\n",
    "item_id = -1\n",
    "logger.info('Write test dataset to %s', test_file)\n",
    "for x in range(len(labels) - trainset):\n",
    "    item_id += 1\n",
    "    datum = caffe.io.array_to_datum(images_test[x], labels_test[x])\n",
    "    keystr = '{:0>8d}'.format(item_id)\n",
    "    lmdb_txn.put( keystr, datum.SerializeToString() )\n",
    "\n",
    "    # write batch\n",
    "    if(item_id + 1) % batch_size == 0:\n",
    "        lmdb_txn.commit()\n",
    "        lmdb_txn = lmdb_env.begin(write=True)\n",
    "        print (item_id + 1)\n",
    "        \n",
    "if (item_id+1) % batch_size != 0:\n",
    "    lmdb_txn.commit()\n",
    "    print 'last test batch'\n",
    "    print (item_id + 1)\n",
    "\n",
    "lmdb_env.close()\n",
    "\n",
    "logger.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import caffe  \n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT = '/home/shihuai02/caffe/examples/mnist/'\n",
    "TEST = DATA_ROOT+'test.csv'\n",
    "OUTPUT = DATA_ROOT+'result.csv'\n",
    "CAFFE_MODEL = DATA_ROOT+'lenet_iter_10000.caffemodel'\n",
    "CAFFE_SOLVER = DATA_ROOT+'lenet_deploy.prototxt'\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "# load test dataset\n",
    "logger.info('Load test dataset from %s', TEST)\n",
    "df = pd.read_csv(TEST)\n",
    "data = df.values\n",
    "\n",
    "np.fromstring(data, dtype=np.uint8)\n",
    "#data = data.astype(np.uint8)\n",
    "\n",
    "testNum = len(data);\n",
    "data = data.reshape((len(data), 28, 28, 1))\n",
    "data = data / 255.\n",
    "logger.info( 'finish load and reshape data')\n",
    "\n",
    "net = caffe.Classifier(CAFFE_SOLVER, CAFFE_MODEL)\n",
    "logger.info('loaded model')\n",
    "\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "# predict\n",
    "logger.info('start predict')\n",
    "iter_k = 0\n",
    "labels = []\n",
    "while True:\n",
    "    result = net.predict([data[iter_k]])\n",
    "    labels.append(result[0].argmax())\n",
    "    iter_k = iter_k + 1\n",
    "    if iter_k == testNum:\n",
    "        break\n",
    "logger.info('Prediction Done')\n",
    "\n",
    "# write to file\n",
    "logger.info('Save result to %s', OUTPUT)\n",
    "if os.path.exists(OUTPUT):\n",
    "    os.remove(OUTPUT)\n",
    "\n",
    "with open(OUTPUT, 'w') as fd:\n",
    "    fd.write('ImageId,Label\\n')\n",
    "    for idx, label in enumerate(labels):\n",
    "        fd.write(str(idx+1))\n",
    "        fd.write(',')\n",
    "        fd.write(str(label))\n",
    "        fd.write('\\n')\n",
    "        \n",
    "logger.info('Finished write result file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
